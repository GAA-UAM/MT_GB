# Multi-Task Gradient Boosting

The code and implementation for "Multi-Task Gradient Boosting" paper, as well as the datasets utilized, are housed in this repository.

The provided algorithm contains an implementation of the Multi-Task Gradient Boosting (MT-GB) algorithm, which extends the popular Gradient Boosting method for both classification and regression problems.

# License
The package is licensed under the GNU Lesser General Public License v2.1.


# Usage

The code for the proposed algorithm is available in this repository for multi-task regression and classification problems. The code is implemented in Python and uses the scikit-learn library.

To run the code, clone this repository and install the necessary libraries. Then, run the `mtgb.py` file to train and test the multi-task gradient boosting algorithm on the provided datasets.

## Documentationd 
To get started with this project, please refer to the [Wiki](https://github.com/GAA-UAM/MT_GB/wiki)."

## Installation
To install the package, clone the repository and use pip to install.
```bash
pip install .
```

<hr>


# Contributions

We warmly welcome contributions to the MT-GB! You can help enhance this algorithm by taking several actions, such as creating an issue to report a bug or suggest an improvement, forking the project and submitting a pull request to the development branch.

## Key members of MT-GB
[Gonzalo Martínez-Muñoz](https://github.com/gmarmu), [Carlos Ruiz Pastor](https://github.com/carlosruizp), [Seyedsaman Emami](https://github.com/samanemami/)


# Release Information

## Version
0.0.1

## Updated
08 May 2023

## Date-released
08 May 2023
